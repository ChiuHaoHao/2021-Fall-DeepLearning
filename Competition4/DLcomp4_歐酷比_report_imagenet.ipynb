{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458cfb65",
   "metadata": {},
   "source": [
    "# Improt some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f511f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2597aae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef1cef",
   "metadata": {},
   "source": [
    "# Some hyperparameters settings\n",
    "* For the image augmentation, use the setting in the block\n",
    "* We think if decrease the information can get in original poison image, model can learn the how to generalize. So we use some image augumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50fc5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset hyperparameters\n",
    "image_size = 224\n",
    "image_channels = 3\n",
    "\n",
    "# Algorithm hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 64  # Corresponds to 200 steps per epoch\n",
    "width = 256\n",
    "temperature = 0.1\n",
    "# Stronger augmentations for contrastive, weaker ones for supervised training\n",
    "contrastive_augmentation = {\"min_area\": 0.75, \"brightness\": 0.9, \"jitter\": 0.5}\n",
    "classification_augmentation = {\"min_area\": 0.75, \"brightness\": 0.9, \"jitter\": 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6404ffa",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "* In this section, we load the dataset from given .npy file.\n",
    "* We bind the image and it label, and batch the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c3a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/x_train_imagenet_unlearn.npy')\n",
    "y_train = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/y_train_imagenet.npy')\n",
    "x_val = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/x_val_imagenet.npy')\n",
    "y_val = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/y_val_imagenet.npy')\n",
    "\n",
    "x_test = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/x_test_imagenet.npy')\n",
    "x_test = tf.image.rgb_to_grayscale(x_test)\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train))\n",
    "train_ds = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "train_dataset_with_label = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_ds_with_label = train_dataset_with_label.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "val_dataset_with_label = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "val_ds_with_label = val_dataset_with_label.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset_with_label = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_ds_with_label = val_dataset_with_label.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2503fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/x_train_imagenet_unlearn.npy')\n",
    "# for idx, img in enumerate(x_train):\n",
    "#     x_train[idx] = gaussian_filter(img, sigma=2)\n",
    "y_train = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/y_train_imagenet.npy')\n",
    "\n",
    "x_val = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/x_val_imagenet.npy')\n",
    "# for idx, img in enumerate(x_val):\n",
    "#     x_val[idx] = gaussian_filter(img, sigma=2)\n",
    "y_val = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/y_val_imagenet.npy')\n",
    "\n",
    "x_test = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/x_test_imagenet.npy')\n",
    "# for idx, img in enumerate(x_test):\n",
    "#     x_test[idx] = gaussian_filter(img, sigma=2)\n",
    "x_test = tf.image.rgb_to_grayscale(x_test)\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train))\n",
    "train_ds = train_dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "train_dataset_with_label = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_ds_with_label = train_dataset_with_label.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "val_dataset_with_label = tf.data.Dataset.from_tensor_slices((x_val,y_val))\n",
    "val_ds_with_label = val_dataset_with_label.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset_with_label = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_ds_with_label = val_dataset_with_label.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe5191",
   "metadata": {},
   "source": [
    "# CNN model\n",
    "\n",
    "We implemented a small ResNet model to train on the dataset. Moreover, instead of using maxout at the last layer, we used average pooling. The main reason of leveraging such feature is that we think the average pixel intensity is more curcial than the existence of a specific pattern. Further more, to prevent overfit, the model is smaller and the channel of CNN is less than a traditional ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8ad053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(tf.keras.Model):\n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(num_channels, padding='same',\n",
    "                                            kernel_size=3, strides=strides)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=1,\n",
    "                                                strides=strides)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return tf.keras.activations.relu(Y)\n",
    "    \n",
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, num_residuals, first_block=False,\n",
    "                 **kwargs):\n",
    "        super(ResnetBlock, self).__init__(**kwargs)\n",
    "        self.residual_layers = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                self.residual_layers.append(\n",
    "                    Residual(num_channels, use_1x1conv=True, strides=1))\n",
    "            else:\n",
    "                self.residual_layers.append(Residual(num_channels))\n",
    "\n",
    "    def call(self, X):\n",
    "        for layer in self.residual_layers.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "\n",
    "class Encoder(tf.keras.Model): # ResNet\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.cov1 = tf.keras.layers.Conv2D(2, kernel_size=7, strides=2, padding='same')\n",
    "        self.batch_norm =  tf.keras.layers.BatchNormalization()\n",
    "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')\n",
    "        self.res_1 = ResnetBlock(2, 2, first_block=True)\n",
    "        self.res_2 = ResnetBlock(4, 2)\n",
    "        self.res_3 = ResnetBlock(8, 2)\n",
    "        self.res_4 = ResnetBlock(16, 2)\n",
    "        self.pool_0 =  tf.keras.layers.AveragePooling2D()\n",
    "        self.pool_1 =  tf.keras.layers.AveragePooling2D()\n",
    "        self.pool_2 =  tf.keras.layers.AveragePooling2D()\n",
    "        self.pool_3 =  tf.keras.layers.AveragePooling2D()\n",
    "        \n",
    "        self.fc = tf.keras.layers.Dense(1024)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.cov1(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool_0(x)\n",
    "        x = self.res_1(x)\n",
    "        x = self.pool_1(x)\n",
    "        x = self.res_2(x)\n",
    "        x = self.pool_2(x)\n",
    "        x = self.res_4(x)\n",
    "        x = self.pool_3(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc72dd",
   "metadata": {},
   "source": [
    "# Check the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9bd1c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 7, 7, 1024), dtype=float32, numpy=\n",
       "array([[[[-2.97182729e-03,  1.19149499e-03,  2.07066443e-03, ...,\n",
       "           1.70820300e-03, -1.52695668e-03,  1.52550652e-04],\n",
       "         [-5.96311467e-04,  1.64727739e-04,  6.43122767e-04, ...,\n",
       "           1.09278866e-04, -1.49633299e-04,  1.32753730e-05],\n",
       "         [-5.44527174e-05,  9.11020106e-06,  6.94519695e-05, ...,\n",
       "          -2.27480978e-05, -2.44529529e-05, -1.31653169e-05],\n",
       "         ...,\n",
       "         [-1.23819577e-08, -3.05741432e-09,  1.47598458e-08, ...,\n",
       "          -1.99148431e-09, -7.37348804e-09, -3.36557648e-09],\n",
       "         [-3.31509611e-08,  1.04255857e-08,  3.73234990e-08, ...,\n",
       "           1.48882036e-08, -2.25056578e-08, -2.08709472e-09],\n",
       "         [-2.29581651e-08,  1.86450961e-08,  2.67401301e-08, ...,\n",
       "           1.91705798e-08, -2.08833271e-08,  9.69132241e-09]],\n",
       "\n",
       "        [[-3.52617539e-03,  1.68864976e-03,  2.35124864e-03, ...,\n",
       "           1.80546253e-03, -1.63540698e-03,  1.19459204e-04],\n",
       "         [-4.58112539e-04, -2.31701633e-05,  6.12510252e-04, ...,\n",
       "           8.52911689e-05, -2.45739473e-04,  1.50596170e-05],\n",
       "         [-5.77033752e-05, -1.38634960e-05,  6.00437343e-05, ...,\n",
       "          -2.49299501e-05, -3.33288190e-05, -2.02205065e-05],\n",
       "         ...,\n",
       "         [-2.98966853e-07,  5.77463517e-08,  4.15963029e-07, ...,\n",
       "          -5.54787682e-08, -1.54869454e-07, -5.99987189e-08],\n",
       "         [-2.06841764e-06, -6.37663504e-08,  2.01424950e-06, ...,\n",
       "           3.06375483e-07, -1.90250148e-06,  7.83280782e-08],\n",
       "         [-1.05871516e-06,  1.12071507e-06,  6.63225933e-07, ...,\n",
       "           2.53654179e-07, -8.88244927e-07,  1.91055705e-07]],\n",
       "\n",
       "        [[-3.65016470e-03,  1.80110196e-03,  2.48566992e-03, ...,\n",
       "           2.01489357e-03, -1.60699291e-03,  1.05159903e-04],\n",
       "         [-4.60659765e-04, -2.98939685e-05,  6.17201207e-04, ...,\n",
       "           9.52704213e-05, -2.73376965e-04,  4.04347084e-05],\n",
       "         [-4.74472181e-05, -1.33798194e-05,  5.40224428e-05, ...,\n",
       "          -2.07336816e-05, -3.54098593e-05, -1.79331619e-05],\n",
       "         ...,\n",
       "         [-1.21170081e-06,  2.52260094e-07,  1.26812006e-06, ...,\n",
       "          -3.08482981e-07, -3.29141130e-07, -5.47662012e-07],\n",
       "         [-1.54271002e-05, -3.63299728e-06,  1.14061759e-05, ...,\n",
       "          -3.45666353e-06, -1.22444080e-05, -1.93353071e-06],\n",
       "         [-1.68745410e-05,  2.48716356e-06,  2.51740694e-05, ...,\n",
       "           8.18840363e-06, -2.24491505e-05,  4.24446625e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.60421464e-03,  1.79070223e-03,  2.46142712e-03, ...,\n",
       "           1.99436885e-03, -1.58429530e-03,  1.06996595e-04],\n",
       "         [-4.57488379e-04, -3.43725151e-05,  6.07623195e-04, ...,\n",
       "           9.52799383e-05, -2.68507720e-04,  3.31448464e-05],\n",
       "         [-4.83574295e-05, -1.38876831e-05,  5.49933975e-05, ...,\n",
       "          -1.72457276e-05, -3.59974038e-05, -2.02659612e-05],\n",
       "         ...,\n",
       "         [-1.09011189e-05,  2.30202954e-06,  1.04941482e-05, ...,\n",
       "           1.05832089e-06, -6.50520906e-06, -2.90877824e-06],\n",
       "         [-1.20574678e-05,  6.18784316e-06,  1.70639614e-05, ...,\n",
       "           7.29248814e-06, -3.24332359e-06, -6.52574681e-06],\n",
       "         [-5.65350383e-05,  2.42931510e-05,  6.27355621e-05, ...,\n",
       "           5.88217008e-05,  4.16123981e-07,  6.05272226e-06]],\n",
       "\n",
       "        [[-3.50926328e-03,  1.71283400e-03,  2.37873034e-03, ...,\n",
       "           1.94467208e-03, -1.52547890e-03,  1.19818149e-04],\n",
       "         [-4.68764076e-04, -2.59649005e-05,  5.79093641e-04, ...,\n",
       "           1.09713925e-04, -2.59875931e-04,  3.71114947e-05],\n",
       "         [-3.99926248e-05, -2.47909502e-05,  4.31150584e-05, ...,\n",
       "          -1.02016129e-05, -4.59807270e-05, -2.19413232e-05],\n",
       "         ...,\n",
       "         [-1.70382082e-05, -2.34337767e-06,  1.34058837e-05, ...,\n",
       "           3.84654140e-06, -1.70718522e-05,  1.05121296e-06],\n",
       "         [-1.04147484e-05,  1.46517561e-06,  4.75113666e-06, ...,\n",
       "           5.36012385e-06, -9.41391318e-06, -7.31045532e-07],\n",
       "         [-1.65473023e-06,  7.72569479e-07,  6.12297890e-06, ...,\n",
       "           5.59202090e-06, -5.26588610e-06,  1.57669513e-06]],\n",
       "\n",
       "        [[-3.23110935e-03,  1.94833323e-03,  2.36787670e-03, ...,\n",
       "           1.96997589e-03, -1.05473481e-03, -3.77470656e-07],\n",
       "         [-2.77162559e-04, -6.04471643e-05,  4.44565841e-04, ...,\n",
       "           9.21167084e-05, -9.82955607e-05,  6.38749771e-05],\n",
       "         [-8.58285857e-05,  2.21881237e-05,  7.31523614e-05, ...,\n",
       "           4.35576403e-05, -4.09578206e-05, -7.18883848e-06],\n",
       "         ...,\n",
       "         [-3.05601643e-05,  8.52840185e-06,  2.81480661e-05, ...,\n",
       "           6.50453421e-06, -1.44171399e-05, -5.14875046e-06],\n",
       "         [-2.40057161e-05,  7.85783868e-06,  2.06349541e-05, ...,\n",
       "           1.48155495e-05, -7.81712151e-06,  1.12540511e-06],\n",
       "         [-2.77224499e-05,  1.04184674e-05,  2.29746165e-05, ...,\n",
       "           1.83930988e-05, -1.38519163e-05,  6.74725743e-06]]],\n",
       "\n",
       "\n",
       "       [[[-3.04167345e-03,  1.21568260e-03,  2.10916391e-03, ...,\n",
       "           1.71344599e-03, -1.58051378e-03,  1.50745444e-04],\n",
       "         [-6.10177231e-04,  1.75131703e-04,  6.66641805e-04, ...,\n",
       "           1.16108858e-04, -1.32444984e-04, -5.09744996e-06],\n",
       "         [-5.41758018e-05,  8.88088380e-06,  6.94166665e-05, ...,\n",
       "          -2.28742501e-05, -2.32874172e-05, -1.36841054e-05],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "        [[-3.56369652e-03,  1.74400175e-03,  2.39049457e-03, ...,\n",
       "           1.84532849e-03, -1.58701418e-03,  9.78786848e-05],\n",
       "         [-4.49217216e-04, -1.94854310e-05,  6.34557276e-04, ...,\n",
       "           9.52712726e-05, -2.24333708e-04,  2.90927474e-05],\n",
       "         [-5.52011952e-05, -1.55427970e-05,  5.69550211e-05, ...,\n",
       "          -2.30548012e-05, -3.51136041e-05, -2.02945412e-05],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "        [[-3.59593052e-03,  1.78274768e-03,  2.45410064e-03, ...,\n",
       "           1.99197070e-03, -1.57215912e-03,  9.99706244e-05],\n",
       "         [-4.50437743e-04, -3.33450953e-05,  6.06230402e-04, ...,\n",
       "           9.51849506e-05, -2.66892021e-04,  3.64214466e-05],\n",
       "         [-4.41565244e-05, -1.55195648e-05,  5.10034333e-05, ...,\n",
       "          -1.88615832e-05, -3.58323996e-05, -1.62380675e-05],\n",
       "         ...,\n",
       "         [-2.25235075e-09,  4.21862517e-10,  3.73227849e-09, ...,\n",
       "          -2.74701373e-10, -1.54408863e-09, -9.14582354e-10],\n",
       "         [-9.11169806e-09,  2.89923618e-09,  1.02712194e-08, ...,\n",
       "           2.60984612e-09, -5.54070700e-09, -8.72414030e-10],\n",
       "         [-5.39379830e-09,  6.58608945e-09,  6.74118006e-09, ...,\n",
       "           5.44616618e-09, -4.26008873e-09,  2.09157092e-09]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.49414186e-03,  1.70447107e-03,  2.36941315e-03, ...,\n",
       "           1.91796303e-03, -1.57674518e-03,  1.07540873e-04],\n",
       "         [-4.63142642e-04, -3.86798311e-05,  5.84900379e-04, ...,\n",
       "           9.93099602e-05, -2.84216105e-04,  3.00409774e-05],\n",
       "         [-4.56158996e-05, -1.36442932e-05,  5.33545317e-05, ...,\n",
       "          -2.06878794e-05, -3.56368037e-05, -1.66725986e-05],\n",
       "         ...,\n",
       "         [-8.98800920e-07,  2.16411458e-08,  9.33317835e-07, ...,\n",
       "          -1.93780579e-07, -8.44276428e-07, -9.41452640e-08],\n",
       "         [-1.40564521e-06, -6.96060809e-08,  1.04214541e-06, ...,\n",
       "          -4.07409487e-07, -1.03141190e-06, -1.79823630e-07],\n",
       "         [-1.47701007e-06,  5.46195565e-07,  2.25831764e-06, ...,\n",
       "           1.02467004e-06, -2.43832574e-06,  1.19582057e-06]],\n",
       "\n",
       "        [[-3.53704114e-03,  1.75217434e-03,  2.41771317e-03, ...,\n",
       "           1.99760706e-03, -1.52713957e-03,  1.14535753e-04],\n",
       "         [-4.60641313e-04, -1.67372036e-05,  5.81283646e-04, ...,\n",
       "           9.72093985e-05, -2.38471534e-04,  3.67040011e-05],\n",
       "         [-2.98984378e-05, -2.38680350e-05,  3.77043252e-05, ...,\n",
       "          -7.26258349e-06, -3.88364970e-05, -8.89189141e-06],\n",
       "         ...,\n",
       "         [-5.94915127e-06, -2.87758849e-06,  5.05976914e-06, ...,\n",
       "          -2.96833633e-07, -9.23155403e-06, -6.36217919e-07],\n",
       "         [-6.27103918e-06, -8.96493830e-08,  5.95919346e-06, ...,\n",
       "           6.06622450e-07, -7.09663254e-06, -4.83882786e-07],\n",
       "         [-1.20107252e-05,  3.88783428e-06,  1.00100142e-05, ...,\n",
       "           1.04283017e-05, -4.93940342e-06,  4.96371649e-06]],\n",
       "\n",
       "        [[-3.12712695e-03,  1.89061300e-03,  2.29688478e-03, ...,\n",
       "           1.91446056e-03, -9.92949703e-04, -4.00510471e-05],\n",
       "         [-3.08856601e-04, -3.90510650e-05,  4.70864587e-04, ...,\n",
       "           1.44800346e-04, -8.49141943e-05,  9.37841978e-05],\n",
       "         [-8.98747603e-05,  2.97807874e-05,  8.44586320e-05, ...,\n",
       "           5.70416851e-05, -5.23553535e-05,  9.08139282e-06],\n",
       "         ...,\n",
       "         [-3.17458725e-05,  1.23994550e-05,  2.67457926e-05, ...,\n",
       "           1.45094955e-05, -1.16563324e-05, -1.93113488e-06],\n",
       "         [-3.98154007e-05,  1.70805833e-05,  3.33422468e-05, ...,\n",
       "           2.50116555e-05, -1.68482784e-05,  8.89343210e-06],\n",
       "         [-1.39568501e-05,  5.80817459e-06,  1.28345710e-05, ...,\n",
       "           8.93036122e-06, -4.49271192e-06,  1.57193074e-06]]],\n",
       "\n",
       "\n",
       "       [[[-3.09206359e-03,  1.25302805e-03,  2.15315144e-03, ...,\n",
       "           1.77528523e-03, -1.58281554e-03,  1.59107978e-04],\n",
       "         [-6.15392753e-04,  1.75201276e-04,  6.69540896e-04, ...,\n",
       "           1.15541130e-04, -1.44109683e-04,  4.32074557e-06],\n",
       "         [-5.69560034e-05,  8.35808169e-06,  7.20579992e-05, ...,\n",
       "          -2.29457874e-05, -2.41860398e-05, -1.39736303e-05],\n",
       "         ...,\n",
       "         [-2.36238816e-06,  1.98114464e-07,  1.37910297e-06, ...,\n",
       "           1.54809925e-07, -1.35529422e-06, -1.94168294e-07],\n",
       "         [-2.78660309e-07, -5.53270247e-08,  3.41199808e-07, ...,\n",
       "          -3.48216744e-08, -1.05622014e-07, -1.77211739e-08],\n",
       "         [-8.72415384e-09,  6.73736844e-10,  1.07284972e-08, ...,\n",
       "          -2.42094433e-09, -3.63436148e-09, -1.29600419e-09]],\n",
       "\n",
       "        [[-3.57643655e-03,  1.77364436e-03,  2.40778946e-03, ...,\n",
       "           1.87268504e-03, -1.58436748e-03,  1.01731210e-04],\n",
       "         [-4.38296469e-04, -1.80928782e-05,  6.28628361e-04, ...,\n",
       "           8.79729560e-05, -2.20149130e-04,  2.53715134e-05],\n",
       "         [-5.44173527e-05, -1.37657962e-05,  5.62996793e-05, ...,\n",
       "          -1.90865248e-05, -3.44411128e-05, -2.03986074e-05],\n",
       "         ...,\n",
       "         [-2.01595094e-06,  2.57130353e-07,  2.67765108e-06, ...,\n",
       "           8.71921060e-08, -1.99100199e-07, -2.13491006e-07],\n",
       "         [-1.65926281e-07,  3.22611804e-08,  1.72437723e-07, ...,\n",
       "          -2.54573855e-08,  3.28117999e-09, -8.18682935e-08],\n",
       "         [-9.09787534e-09, -8.95672425e-10,  1.13202603e-08, ...,\n",
       "          -1.75985337e-09, -1.43982026e-09, -4.35455494e-09]],\n",
       "\n",
       "        [[-3.53980646e-03,  1.72723632e-03,  2.39360752e-03, ...,\n",
       "           1.92676298e-03, -1.57074945e-03,  1.02464270e-04],\n",
       "         [-4.63409116e-04, -4.04982311e-05,  5.99445077e-04, ...,\n",
       "           1.06242245e-04, -2.88959767e-04,  3.63371037e-05],\n",
       "         [-4.71518251e-05, -1.48826484e-05,  5.45961593e-05, ...,\n",
       "          -1.93272190e-05, -3.59827318e-05, -1.73631688e-05],\n",
       "         ...,\n",
       "         [-9.57175644e-07,  3.37605393e-08,  1.26430302e-06, ...,\n",
       "           4.28652271e-07, -3.55319372e-07,  5.65317713e-08],\n",
       "         [-8.34507503e-08, -2.04479509e-08,  9.51229637e-08, ...,\n",
       "           1.13356036e-08, -9.78246391e-08, -1.21634232e-08],\n",
       "         [-1.61445746e-09, -3.78404502e-10,  2.06470552e-09, ...,\n",
       "          -1.61431601e-09, -4.80575624e-09, -3.63633207e-10]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.58159025e-03,  1.75682933e-03,  2.42330506e-03, ...,\n",
       "           1.95318414e-03, -1.58339017e-03,  1.13552844e-04],\n",
       "         [-4.68626415e-04, -3.94836861e-05,  6.03559776e-04, ...,\n",
       "           1.06160529e-04, -2.88188749e-04,  3.51019517e-05],\n",
       "         [-4.62677417e-05, -1.47325982e-05,  5.30045545e-05, ...,\n",
       "          -2.07433422e-05, -3.69819754e-05, -1.73885182e-05],\n",
       "         ...,\n",
       "         [-2.40951522e-06, -1.46690218e-06,  2.67284304e-06, ...,\n",
       "          -7.87794420e-07, -3.57545377e-06,  8.81978281e-07],\n",
       "         [-1.89906848e-06,  5.35864444e-07,  1.22731660e-06, ...,\n",
       "           3.18357280e-07, -1.90369326e-06,  7.52245271e-08],\n",
       "         [-1.49322580e-06,  2.25464873e-08,  1.27997976e-06, ...,\n",
       "           1.45409729e-07, -1.18705634e-06,  2.13510873e-07]],\n",
       "\n",
       "        [[-3.61078023e-03,  1.80312572e-03,  2.47667427e-03, ...,\n",
       "           2.05162959e-03, -1.55504281e-03,  1.13334267e-04],\n",
       "         [-4.59486619e-04, -1.25292327e-05,  5.94634505e-04, ...,\n",
       "           9.75033254e-05, -2.41217480e-04,  4.15583781e-05],\n",
       "         [-2.82061937e-05, -1.72022847e-05,  2.96718317e-05, ...,\n",
       "          -1.12889174e-05, -2.96198596e-05, -1.41036107e-05],\n",
       "         ...,\n",
       "         [-1.82617259e-05,  8.97416840e-07,  1.45297317e-05, ...,\n",
       "           7.43049623e-06, -1.42281287e-05,  6.10738562e-06],\n",
       "         [-1.63545192e-05,  4.45335843e-07,  1.46713119e-05, ...,\n",
       "           1.60796924e-06, -8.69912310e-06, -2.70314035e-06],\n",
       "         [-9.50905269e-06,  2.01192208e-07,  1.14175882e-05, ...,\n",
       "          -1.43805175e-06, -1.58485527e-05,  3.72400541e-06]],\n",
       "\n",
       "        [[-3.12756863e-03,  1.91357348e-03,  2.29690340e-03, ...,\n",
       "           1.92073407e-03, -9.97834839e-04, -5.46685806e-06],\n",
       "         [-2.62598653e-04, -6.92454705e-05,  4.21757344e-04, ...,\n",
       "           9.41283215e-05, -1.02242746e-04,  5.87299219e-05],\n",
       "         [-8.37625612e-06, -9.37942059e-06,  1.45247313e-05, ...,\n",
       "          -5.80109054e-06, -1.75575587e-05, -7.43886221e-06],\n",
       "         ...,\n",
       "         [-4.78606889e-05,  2.01917810e-05,  4.07376865e-05, ...,\n",
       "           3.11859658e-05, -1.79807630e-05,  9.10821200e-06],\n",
       "         [-1.49566094e-05,  5.63467165e-06,  1.54167301e-05, ...,\n",
       "           5.44907516e-06, -4.63680090e-06, -9.28793543e-06],\n",
       "         [-9.28530208e-05,  4.04311577e-05,  7.82997449e-05, ...,\n",
       "           7.10456516e-05, -4.23357778e-05,  2.94922411e-05]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-3.09420028e-03,  1.25418545e-03,  2.15786230e-03, ...,\n",
       "           1.78458425e-03, -1.58456236e-03,  1.58750117e-04],\n",
       "         [-6.15794619e-04,  1.74673158e-04,  6.68142166e-04, ...,\n",
       "           1.14220180e-04, -1.45044789e-04,  6.96580537e-06],\n",
       "         [-5.47176169e-05,  8.52332596e-06,  6.92259200e-05, ...,\n",
       "          -2.28613062e-05, -2.33823666e-05, -1.35629007e-05],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "        [[-3.57009633e-03,  1.78358727e-03,  2.41153804e-03, ...,\n",
       "           1.88942766e-03, -1.57490256e-03,  1.04266983e-04],\n",
       "         [-4.29081672e-04, -1.76269859e-05,  6.25138811e-04, ...,\n",
       "           8.45664472e-05, -2.15209846e-04,  2.52657228e-05],\n",
       "         [-5.37434062e-05, -1.54479822e-05,  5.56923078e-05, ...,\n",
       "          -2.20470611e-05, -3.49778602e-05, -1.99925125e-05],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "        [[-3.50729749e-03,  1.70866214e-03,  2.36899429e-03, ...,\n",
       "           1.90509029e-03, -1.56116718e-03,  1.06683328e-04],\n",
       "         [-4.62130614e-04, -4.09209533e-05,  5.91975520e-04, ...,\n",
       "           1.07426116e-04, -2.90131051e-04,  3.47726418e-05],\n",
       "         [-4.66781494e-05, -1.44629093e-05,  5.35652762e-05, ...,\n",
       "          -2.13667117e-05, -3.69246372e-05, -1.66177524e-05],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.58590344e-03,  1.74590887e-03,  2.41805543e-03, ...,\n",
       "           1.94234890e-03, -1.60011789e-03,  1.14025395e-04],\n",
       "         [-4.72438551e-04, -4.01864381e-05,  6.02328160e-04, ...,\n",
       "           1.10391557e-04, -2.86154624e-04,  3.19722167e-05],\n",
       "         [-4.53865432e-05, -1.48436520e-05,  5.26243239e-05, ...,\n",
       "          -2.15576420e-05, -3.73251969e-05, -1.64302055e-05],\n",
       "         ...,\n",
       "         [-1.27360636e-06,  2.26970331e-09,  1.30511307e-06, ...,\n",
       "           3.35848327e-08, -1.58022021e-06,  3.61198538e-08],\n",
       "         [-1.67756048e-06, -5.44356560e-09,  1.31756838e-06, ...,\n",
       "          -4.38233805e-08, -1.55454325e-06,  3.65615335e-07],\n",
       "         [-4.92360414e-07,  1.33404683e-07,  3.91465079e-07, ...,\n",
       "           3.19741567e-08, -1.13088595e-06, -4.53239402e-08]],\n",
       "\n",
       "        [[-3.60871037e-03,  1.81520102e-03,  2.48382124e-03, ...,\n",
       "           2.06773286e-03, -1.53476442e-03,  1.05485313e-04],\n",
       "         [-4.51258587e-04, -3.36122253e-06,  5.94487647e-04, ...,\n",
       "           9.87606400e-05, -2.25635376e-04,  4.56915004e-05],\n",
       "         [-3.04448185e-05, -2.26333923e-05,  3.30987132e-05, ...,\n",
       "          -8.19835168e-06, -3.64965126e-05, -9.39656547e-06],\n",
       "         ...,\n",
       "         [-1.15211942e-05, -3.89045817e-06,  8.11953123e-06, ...,\n",
       "           1.00195791e-06, -1.23011514e-05, -1.03511752e-06],\n",
       "         [-1.89038437e-05, -2.09032214e-06,  2.08565198e-05, ...,\n",
       "          -1.22214294e-06, -1.75956429e-05,  4.49754771e-06],\n",
       "         [-9.07641970e-06, -1.81575547e-06,  6.63489345e-06, ...,\n",
       "           3.85470776e-06, -1.31565248e-05,  3.68037831e-06]],\n",
       "\n",
       "        [[-3.09155951e-03,  1.89681898e-03,  2.27272604e-03, ...,\n",
       "           1.90827018e-03, -9.79823642e-04, -6.72419901e-06],\n",
       "         [-3.00688465e-04, -4.79310329e-05,  4.49594081e-04, ...,\n",
       "           1.36647519e-04, -1.00622849e-04,  8.05494710e-05],\n",
       "         [-3.70244452e-05,  6.85608165e-06,  4.22000376e-05, ...,\n",
       "           2.36460201e-05, -2.85784154e-05, -6.90069328e-06],\n",
       "         ...,\n",
       "         [-1.88992544e-05,  6.83271855e-06,  1.63776276e-05, ...,\n",
       "           3.13743885e-06, -5.39585790e-06, -1.18101170e-05],\n",
       "         [-9.11355091e-05,  4.52168169e-05,  7.99357731e-05, ...,\n",
       "           7.26307262e-05, -3.46203196e-05,  3.30926196e-05],\n",
       "         [-2.02462670e-05,  6.47708157e-06,  2.20932216e-05, ...,\n",
       "           1.85272268e-06, -9.47406443e-06, -2.28483441e-06]]],\n",
       "\n",
       "\n",
       "       [[[-3.09553137e-03,  1.24285487e-03,  2.14689970e-03, ...,\n",
       "           1.75608275e-03, -1.59618864e-03,  1.61301301e-04],\n",
       "         [-6.20750303e-04,  1.76997375e-04,  6.74834475e-04, ...,\n",
       "           1.19077224e-04, -1.43876940e-04,  1.06440245e-06],\n",
       "         [-5.55208535e-05,  8.85215741e-06,  7.06819919e-05, ...,\n",
       "          -2.35435236e-05, -2.35014868e-05, -1.36799890e-05],\n",
       "         ...,\n",
       "         [-1.70164412e-07,  2.60030131e-09,  2.06146083e-07, ...,\n",
       "          -5.16887866e-08, -3.55745051e-08, -7.70338460e-08],\n",
       "         [-1.66001007e-06, -2.59872650e-07,  1.42064073e-06, ...,\n",
       "          -2.26349599e-07, -1.42093620e-06, -2.08153267e-07],\n",
       "         [-1.98935209e-06,  5.22033702e-07,  2.50730250e-06, ...,\n",
       "           1.72319915e-06, -2.79046299e-06,  1.70443877e-06]],\n",
       "\n",
       "        [[-3.61851742e-03,  1.78622792e-03,  2.43867398e-03, ...,\n",
       "           1.90435781e-03, -1.60943554e-03,  1.04653154e-04],\n",
       "         [-4.47136379e-04, -1.64372250e-05,  6.35147269e-04, ...,\n",
       "           8.83694083e-05, -2.26634802e-04,  2.80054792e-05],\n",
       "         [-5.49965516e-05, -1.54229656e-05,  5.66416202e-05, ...,\n",
       "          -2.24310152e-05, -3.51655544e-05, -2.05920751e-05],\n",
       "         ...,\n",
       "         [-2.86604916e-07,  8.37593177e-08,  3.28333726e-07, ...,\n",
       "          -1.34852513e-07, -5.15834202e-08, -2.60280615e-07],\n",
       "         [-4.22065432e-06, -3.64603949e-07,  3.83692395e-06, ...,\n",
       "          -4.11385429e-07, -1.77454240e-06, -2.08716460e-06],\n",
       "         [-1.24523622e-05,  5.53125938e-06,  1.33429940e-05, ...,\n",
       "           1.33396097e-05, -7.96244149e-06,  9.41348026e-06]],\n",
       "\n",
       "        [[-3.59979598e-03,  1.79897994e-03,  2.45455047e-03, ...,\n",
       "           1.99646922e-03, -1.56904384e-03,  1.02226069e-04],\n",
       "         [-4.51798522e-04, -3.51817689e-05,  6.06415444e-04, ...,\n",
       "           9.73208225e-05, -2.73093610e-04,  3.60921877e-05],\n",
       "         [-4.51156266e-05, -1.53174369e-05,  5.18728957e-05, ...,\n",
       "          -1.93481519e-05, -3.65751694e-05, -1.67481248e-05],\n",
       "         ...,\n",
       "         [-1.45053889e-07,  2.40928614e-07,  3.34518688e-07, ...,\n",
       "           4.56342057e-08, -9.61909379e-08, -4.10374383e-07],\n",
       "         [-2.70580927e-06,  2.77475397e-06,  4.15546720e-06, ...,\n",
       "           3.34579363e-06, -2.65097214e-07, -1.76789501e-06],\n",
       "         [-3.10502655e-05,  1.26084224e-05,  2.74221766e-05, ...,\n",
       "           3.18056045e-05, -8.96437177e-06,  7.53193171e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.57344560e-03,  1.75891886e-03,  2.43318593e-03, ...,\n",
       "           1.97217939e-03, -1.57164421e-03,  9.94438815e-05],\n",
       "         [-4.53629036e-04, -3.56277560e-05,  6.06432208e-04, ...,\n",
       "           9.87698440e-05, -2.70431658e-04,  3.90457280e-05],\n",
       "         [-4.63020442e-05, -1.43260704e-05,  5.46389492e-05, ...,\n",
       "          -2.00012328e-05, -3.69090340e-05, -1.69830073e-05],\n",
       "         ...,\n",
       "         [-5.56293003e-07,  4.65984130e-07,  5.65334744e-07, ...,\n",
       "          -8.20893007e-08, -8.14559769e-07, -1.76900002e-07],\n",
       "         [-1.22301594e-06,  3.80804750e-07,  1.20839422e-06, ...,\n",
       "           3.53099381e-07, -9.34057311e-07, -3.52152512e-07],\n",
       "         [-2.88079241e-06,  1.03562195e-06,  3.11609188e-06, ...,\n",
       "           3.03454635e-06, -3.15037425e-07,  1.96044056e-07]],\n",
       "\n",
       "        [[-3.54725821e-03,  1.74778013e-03,  2.41796346e-03, ...,\n",
       "           1.98760070e-03, -1.53637922e-03,  1.20121578e-04],\n",
       "         [-4.69335821e-04, -1.23635737e-05,  5.78090141e-04, ...,\n",
       "           1.07643675e-04, -2.51455116e-04,  3.20449653e-05],\n",
       "         [-3.51858325e-05, -3.21128973e-05,  5.02901603e-05, ...,\n",
       "          -4.71508474e-06, -5.45998773e-05, -1.08331942e-05],\n",
       "         ...,\n",
       "         [-1.33354051e-05,  1.19192578e-06,  7.49322726e-06, ...,\n",
       "           2.60690672e-06, -1.10463407e-05, -4.13161203e-08],\n",
       "         [-5.53585915e-06, -3.12647444e-06,  5.73605939e-06, ...,\n",
       "          -6.77763694e-07, -8.29079272e-06,  2.24671203e-06],\n",
       "         [-3.29091176e-06,  5.35032370e-07,  1.22804033e-06, ...,\n",
       "           7.50619733e-07, -3.19337869e-06,  4.96542043e-07]],\n",
       "\n",
       "        [[-3.17285443e-03,  1.91826618e-03,  2.32903589e-03, ...,\n",
       "           1.94354774e-03, -1.01871288e-03, -1.03207813e-05],\n",
       "         [-3.10080068e-04, -3.91284593e-05,  4.69448947e-04, ...,\n",
       "           1.31603985e-04, -9.99302574e-05,  8.61873268e-05],\n",
       "         [-1.54310648e-04,  6.18455088e-05,  1.26980798e-04, ...,\n",
       "           8.72370147e-05, -7.91592101e-05,  1.50813903e-05],\n",
       "         ...,\n",
       "         [-1.84382789e-05,  5.64173115e-06,  2.29064390e-05, ...,\n",
       "           3.05209505e-06, -2.64611685e-06, -3.13780765e-06],\n",
       "         [-3.54096883e-05,  1.45996992e-05,  3.09679308e-05, ...,\n",
       "           2.42270035e-05, -1.47971941e-05,  7.92603532e-06],\n",
       "         [-5.08611402e-06,  9.55449423e-07,  6.36980485e-06, ...,\n",
       "          -5.14839869e-08,  5.71027350e-08, -1.46244679e-06]]],\n",
       "\n",
       "\n",
       "       [[[-3.15085799e-03,  1.27706781e-03,  2.19140574e-03, ...,\n",
       "           1.81350438e-03, -1.62275403e-03,  1.63820529e-04],\n",
       "         [-6.31840318e-04,  1.77877475e-04,  6.81829173e-04, ...,\n",
       "           1.15942850e-04, -1.51260101e-04,  6.28178486e-06],\n",
       "         [-5.68275464e-05,  8.86133421e-06,  7.20085736e-05, ...,\n",
       "          -2.37455315e-05, -2.48376582e-05, -1.42980152e-05],\n",
       "         ...,\n",
       "         [-9.44293879e-06, -4.83012286e-07,  8.84823930e-06, ...,\n",
       "          -5.81137272e-07, -1.05989293e-05,  3.74591559e-06],\n",
       "         [-6.70101508e-06, -6.02121304e-07,  3.71210535e-06, ...,\n",
       "           3.49513357e-07, -6.38448046e-06,  8.76653303e-07],\n",
       "         [-1.63337529e-06, -7.36004679e-08,  1.75898072e-06, ...,\n",
       "           1.96000755e-07, -4.98636609e-07,  1.50767061e-08]],\n",
       "\n",
       "        [[-3.67763173e-03,  1.81332196e-03,  2.47198064e-03, ...,\n",
       "           1.92397169e-03, -1.64027442e-03,  1.06438987e-04],\n",
       "         [-4.51106724e-04, -1.83240027e-05,  6.40658021e-04, ...,\n",
       "           9.11710667e-05, -2.26525357e-04,  2.40370664e-05],\n",
       "         [-5.58755528e-05, -1.58132243e-05,  5.71462078e-05, ...,\n",
       "          -2.33916671e-05, -3.57846475e-05, -2.07489938e-05],\n",
       "         ...,\n",
       "         [-4.02743062e-05,  2.25482945e-05,  3.72579780e-05, ...,\n",
       "           4.07040025e-05, -1.40954689e-05,  1.63860223e-05],\n",
       "         [-9.70562451e-06,  2.69952398e-06,  1.17400159e-05, ...,\n",
       "           1.74267893e-06, -3.40536212e-06, -2.00449904e-06],\n",
       "         [-2.56227463e-06,  1.69981149e-07,  3.50935602e-06, ...,\n",
       "           3.91611223e-07, -2.26486031e-06,  4.93872847e-07]],\n",
       "\n",
       "        [[-3.62757873e-03,  1.80532003e-03,  2.46746792e-03, ...,\n",
       "           2.00305483e-03, -1.57239963e-03,  1.02883634e-04],\n",
       "         [-4.59776493e-04, -3.68621950e-05,  6.16251200e-04, ...,\n",
       "           1.03219143e-04, -2.81822722e-04,  4.06049621e-05],\n",
       "         [-4.63628603e-05, -1.52434777e-05,  5.26146905e-05, ...,\n",
       "          -2.04463504e-05, -3.79430021e-05, -1.76394897e-05],\n",
       "         ...,\n",
       "         [-1.04114579e-05,  5.04166883e-06,  1.32880950e-05, ...,\n",
       "           9.56804524e-06,  2.93829794e-06, -1.09674511e-06],\n",
       "         [-7.87860608e-06,  1.10984388e-06,  8.66227583e-06, ...,\n",
       "           4.24911423e-06, -6.61465265e-07, -2.63434390e-06],\n",
       "         [-1.48579284e-05,  5.23022618e-06,  1.34812281e-05, ...,\n",
       "           1.46490647e-05, -9.70882229e-06,  8.10813708e-06]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.64434766e-03,  1.81852607e-03,  2.49212980e-03, ...,\n",
       "           2.03069951e-03, -1.59739493e-03,  1.08170039e-04],\n",
       "         [-4.56763752e-04, -3.35891018e-05,  6.11940166e-04, ...,\n",
       "           9.59270401e-05, -2.62452988e-04,  3.38763020e-05],\n",
       "         [-4.60495321e-05, -1.56775295e-05,  5.32290214e-05, ...,\n",
       "          -1.89441162e-05, -3.66572749e-05, -1.76697376e-05],\n",
       "         ...,\n",
       "         [-3.09985103e-06,  2.24077027e-07,  2.46460695e-06, ...,\n",
       "          -3.04838949e-07, -3.10025212e-06,  3.65136202e-07],\n",
       "         [-1.46064292e-06,  9.12015480e-07,  5.85894782e-07, ...,\n",
       "           4.66325105e-07, -1.80336394e-06,  3.23563199e-07],\n",
       "         [-8.24107588e-07,  2.37713067e-07,  2.25269537e-06, ...,\n",
       "           1.20388768e-06, -5.67916913e-07,  1.99800880e-07]],\n",
       "\n",
       "        [[-3.49099515e-03,  1.74690597e-03,  2.38624495e-03, ...,\n",
       "           1.97473471e-03, -1.47642393e-03,  1.06832282e-04],\n",
       "         [-4.47707978e-04, -1.96650126e-05,  5.73453261e-04, ...,\n",
       "           1.10730769e-04, -2.33463317e-04,  3.36871999e-05],\n",
       "         [-4.85180863e-05, -2.57756856e-05,  5.12448241e-05, ...,\n",
       "          -1.04860501e-05, -5.81995773e-05, -2.08411420e-05],\n",
       "         ...,\n",
       "         [-2.49228870e-05, -1.45294789e-05,  2.73281767e-05, ...,\n",
       "          -2.07065432e-06, -3.91195063e-05,  1.42946092e-05],\n",
       "         [-1.75243858e-05,  3.47840501e-06,  8.05513992e-06, ...,\n",
       "           2.83450140e-06, -1.48404897e-05,  9.41727137e-07],\n",
       "         [-4.68369672e-06, -1.55620558e-06,  5.18265279e-06, ...,\n",
       "          -1.52417300e-07, -5.64085713e-06,  1.24129383e-06]],\n",
       "\n",
       "        [[-3.05228797e-03,  1.85111258e-03,  2.25328235e-03, ...,\n",
       "           1.87901396e-03, -9.66742460e-04, -2.90498392e-05],\n",
       "         [-3.05218709e-04, -4.76827445e-05,  4.50869993e-04, ...,\n",
       "           1.15883369e-04, -1.01734026e-04,  7.05104030e-05],\n",
       "         [-1.65008547e-04,  5.92494580e-05,  1.31795547e-04, ...,\n",
       "           8.28739721e-05, -8.06343596e-05,  2.14511260e-06],\n",
       "         ...,\n",
       "         [-1.63653618e-04,  6.70318332e-05,  1.37306386e-04, ...,\n",
       "           9.04485350e-05, -7.93259314e-05,  3.87816763e-05],\n",
       "         [-3.26648369e-05,  9.15929104e-06,  3.74559604e-05, ...,\n",
       "           6.60378282e-06, -2.53339726e-06, -5.73143370e-06],\n",
       "         [-2.07835546e-05,  7.46019259e-06,  1.97985901e-05, ...,\n",
       "           1.19561919e-05, -9.46682212e-06,  4.51097503e-06]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = tf.random.uniform(shape=[64,224,224,1], minval=0.7, maxval=1.)\n",
    "\n",
    "g = Encoder()\n",
    "g(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63742181",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "This block implement the augmentation in our project. We used 5 different augmentations, which are Random Flip, Random Translation, Random Zoom, GrayScale and sobel edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eef0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomColorAffine(layers.Layer):\n",
    "    def __init__(self, brightness=0, jitter=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.brightness = brightness\n",
    "        self.jitter = jitter\n",
    "\n",
    "    def call(self, images, training=True):\n",
    "        if training:\n",
    "            batch_size = tf.shape(images)[0]\n",
    "\n",
    "            # Same for all colors\n",
    "            brightness_scales = 1 + tf.random.uniform(\n",
    "                (batch_size, 1, 1, 1), minval=-self.brightness, maxval=self.brightness\n",
    "            )\n",
    "            # Different for all colors\n",
    "            jitter_matrices = tf.random.uniform(\n",
    "                (batch_size, 1, 3, 3), minval=-self.jitter, maxval=self.jitter\n",
    "            )\n",
    "\n",
    "            color_transforms = (\n",
    "                tf.eye(3, batch_shape=[batch_size, 1]) * brightness_scales\n",
    "            )\n",
    "            images = tf.clip_by_value(tf.matmul(images, color_transforms), 0, 1)\n",
    "        return images\n",
    "\n",
    "\n",
    "class Grayscale(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.image.rgb_to_grayscale(x)\n",
    "\n",
    "class Canny(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "#         blurred = cv2.GaussianBlur(x.numpy(), (5, 5), 0)\n",
    "#         canny = cv2.Canny(blurred, 30, 150)\n",
    "        return tf.image.sobel_edges(x)\n",
    "\n",
    "# Image augmentation module\n",
    "def get_augmenter(min_area, brightness, jitter):\n",
    "    zoom_factor = 1.0 - tf.sqrt(min_area)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(image_size, image_size, image_channels)),\n",
    "#             layers.experimental.preprocessing.RandomCrop(200, 200),\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n",
    "            layers.experimental.preprocessing.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n",
    "            RandomColorAffine(brightness, jitter),\n",
    "            Grayscale(),\n",
    "            Canny(),\n",
    "            layers.Reshape((224, 224, 2)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Image augmentation module\n",
    "def get_augmenter_val(min_area, brightness, jitter):\n",
    "    zoom_factor = 1.0 - tf.sqrt(min_area)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(image_size, image_size, image_channels)),\n",
    "            Grayscale(),\n",
    "            Canny(),\n",
    "            layers.Reshape((224, 224, 2)),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa559d3e",
   "metadata": {},
   "source": [
    "# Model we used to classify\n",
    "* We designed a model as below, we also used l2 norm to regularize our model.\n",
    "* We had tried deeper layer, but it seemed useless to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d05d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier(tf.keras.Model): # ResNet\n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.encoder.trainable = True\n",
    "        # self.fc3 = tf.keras.layers.Dense(1024, kernel_regularizer=l2(0.01))\n",
    "        self.fc1 = tf.keras.layers.Dense(512, kernel_regularizer=l2(0.01))\n",
    "        self.fc3 = tf.keras.layers.Dense(256)\n",
    "        self.fc2 = tf.keras.layers.Dense(1)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94bec6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d318616d",
   "metadata": {},
   "source": [
    "# Training\n",
    "* We tried Adam and SGD for our optimizer, and we find Adam had better performance.\n",
    "* Used BCE loss in this case because it was a binary problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86224451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "optimizer = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-8)\n",
    "# optimizer = tf.keras.optimizers.SGD(\n",
    "#     learning_rate=0.001, momentum=0.0, nesterov=False, name='SGD'\n",
    "# )\n",
    "\n",
    "def binary_accuracy(y_true, y_pred):\n",
    "    '''Calculates the mean accuracy rate across all predictions for binary\n",
    "    classification problems.\n",
    "    '''\n",
    "    \n",
    "    y_pred = tf.nn.sigmoid(y_pred)\n",
    "    # print(y_pred)\n",
    "    # print(y_pred.shape)\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "\n",
    "@tf.function\n",
    "def train_step_classification(img, label):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        logit = model(img)\n",
    "        loss = cross_entropy(label, logit)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, logit\n",
    "\n",
    "@tf.function\n",
    "def test_step(img, label):\n",
    "    logit = model(img)\n",
    "    return binary_accuracy(label, logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985293f7",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbc05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/l2-canny-slim\"\n",
    "# ./checkpoints/term_project_haowei_early_stop\n",
    "ckpt = tf.train.Checkpoint(model=model,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985f1a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path_75 = \"./checkpoints/l2-tune/over75\"\n",
    "# # ./checkpoints/term_project_haowei_early_stop\n",
    "# ckpt_75 = tf.train.Checkpoint(model=model,\n",
    "#                            optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager_75 = tf.train.CheckpointManager(ckpt_75, checkpoint_path, max_to_keep=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c160b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt.restore(checkpoint_path + '/ckpt-1313')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286101e6",
   "metadata": {},
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a10504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 0 at ./checkpoints/l2-canny-slim/ckpt-1\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method RandomColorAffine.call of <__main__.RandomColorAffine object at 0x7f8e4596d710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method RandomColorAffine.call of <__main__.RandomColorAffine object at 0x7f8e4596d710>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1 Batch 0 Loss 0.6884665\n",
      "Epoch 1 Loss 0.6551462\n",
      "test accuracy:  0.6707356770833334\n",
      "train accuracy:  0.6883928571428571\n",
      "Time taken for 1 epoch: 8.17 secs\n",
      "\n",
      "Saving checkpoint for epoch 1 at ./checkpoints/l2-canny-slim/ckpt-2\n",
      "Epoch 2 Batch 0 Loss 0.5733029\n",
      "Epoch 2 Loss 0.6174582\n",
      "test accuracy:  0.70703125\n",
      "train accuracy:  0.7227678571428572\n",
      "Time taken for 1 epoch: 6.82 secs\n",
      "\n",
      "Saving checkpoint for epoch 2 at ./checkpoints/l2-canny-slim/ckpt-3\n",
      "Epoch 3 Batch 0 Loss 0.5519198\n",
      "Epoch 3 Loss 0.4429387\n",
      "test accuracy:  0.6778971354166666\n",
      "train accuracy:  0.7598214285714285\n",
      "Time taken for 1 epoch: 6.78 secs\n",
      "\n",
      "Saving checkpoint for epoch 3 at ./checkpoints/l2-canny-slim/ckpt-4\n",
      "Epoch 4 Batch 0 Loss 0.4848891\n",
      "Epoch 4 Loss 0.4614781\n",
      "test accuracy:  0.6863606770833334\n",
      "train accuracy:  0.7665178571428571\n",
      "Time taken for 1 epoch: 6.71 secs\n",
      "\n",
      "Saving checkpoint for epoch 4 at ./checkpoints/l2-canny-slim/ckpt-5\n",
      "Epoch 5 Batch 0 Loss 0.4177216\n",
      "Epoch 5 Loss 0.4366623\n",
      "test accuracy:  0.7062174479166666\n",
      "train accuracy:  0.790625\n",
      "Time taken for 1 epoch: 6.71 secs\n",
      "\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/l2-canny-slim/ckpt-6\n",
      "Epoch 6 Batch 0 Loss 0.4481109\n",
      "Epoch 6 Loss 0.4329417\n",
      "test accuracy:  0.6726888020833334\n",
      "train accuracy:  0.7883928571428571\n",
      "Time taken for 1 epoch: 6.80 secs\n",
      "\n",
      "Saving checkpoint for epoch 6 at ./checkpoints/l2-canny-slim/ckpt-7\n",
      "Epoch 7 Batch 0 Loss 0.4838943\n",
      "Epoch 7 Loss 0.4028863\n",
      "test accuracy:  0.7171223958333334\n",
      "train accuracy:  0.7973214285714286\n",
      "Time taken for 1 epoch: 6.80 secs\n",
      "\n",
      "Saving checkpoint for epoch 7 at ./checkpoints/l2-canny-slim/ckpt-8\n",
      "Epoch 8 Batch 0 Loss 0.3406396\n",
      "Epoch 8 Loss 0.3387064\n",
      "test accuracy:  0.7174479166666666\n",
      "train accuracy:  0.8285714285714286\n",
      "Time taken for 1 epoch: 6.63 secs\n",
      "\n",
      "Saving checkpoint for epoch 8 at ./checkpoints/l2-canny-slim/ckpt-9\n",
      "Epoch 9 Batch 0 Loss 0.3799031\n",
      "Epoch 9 Loss 0.3696560\n",
      "test accuracy:  0.6935221354166666\n",
      "train accuracy:  0.8205357142857143\n",
      "Time taken for 1 epoch: 6.81 secs\n",
      "\n",
      "Saving checkpoint for epoch 9 at ./checkpoints/l2-canny-slim/ckpt-10\n",
      "Epoch 10 Batch 0 Loss 0.4385385\n",
      "Epoch 10 Loss 0.2881637\n",
      "test accuracy:  0.7431640625\n",
      "train accuracy:  0.8370535714285714\n",
      "Time taken for 1 epoch: 6.73 secs\n",
      "\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/l2-canny-slim/ckpt-11\n",
      "Epoch 11 Batch 0 Loss 0.2256590\n",
      "Epoch 11 Loss 0.2674185\n",
      "test accuracy:  0.7433268229166666\n",
      "train accuracy:  0.8419642857142857\n",
      "Time taken for 1 epoch: 6.86 secs\n",
      "\n",
      "Saving checkpoint for epoch 11 at ./checkpoints/l2-canny-slim/ckpt-12\n",
      "Epoch 12 Batch 0 Loss 0.1762783\n",
      "Epoch 12 Loss 0.3119725\n",
      "test accuracy:  0.7122395833333334\n",
      "train accuracy:  0.8486607142857143\n",
      "Time taken for 1 epoch: 7.30 secs\n",
      "\n",
      "Saving checkpoint for epoch 12 at ./checkpoints/l2-canny-slim/ckpt-13\n",
      "Epoch 13 Batch 0 Loss 0.2533200\n",
      "Epoch 13 Loss 0.2487614\n",
      "test accuracy:  0.74853515625\n",
      "train accuracy:  0.8647321428571428\n",
      "Time taken for 1 epoch: 6.71 secs\n",
      "\n",
      "Saving checkpoint for epoch 13 at ./checkpoints/l2-canny-slim/ckpt-14\n",
      "Epoch 14 Batch 0 Loss 0.2739522\n",
      "Epoch 14 Loss 0.2507820\n",
      "test accuracy:  0.7434895833333334\n",
      "train accuracy:  0.8571428571428571\n",
      "Time taken for 1 epoch: 6.88 secs\n",
      "\n",
      "Saving checkpoint for epoch 14 at ./checkpoints/l2-canny-slim/ckpt-15\n",
      "Epoch 15 Batch 0 Loss 0.1862682\n",
      "Epoch 15 Loss 0.3725536\n",
      "test accuracy:  0.7101236979166666\n",
      "train accuracy:  0.8754464285714286\n",
      "Time taken for 1 epoch: 6.93 secs\n",
      "\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/l2-canny-slim/ckpt-16\n",
      "Epoch 16 Batch 0 Loss 0.2209922\n",
      "Epoch 16 Loss 0.2294655\n",
      "test accuracy:  0.7509765625\n",
      "train accuracy:  0.8794642857142857\n",
      "Time taken for 1 epoch: 6.75 secs\n",
      "\n",
      "Saving checkpoint for epoch 16 at ./checkpoints/l2-canny-slim/ckpt-17\n",
      "Epoch 17 Batch 0 Loss 0.2971809\n",
      "Epoch 17 Loss 0.2662870\n",
      "test accuracy:  0.73046875\n",
      "train accuracy:  0.8794642857142857\n",
      "Time taken for 1 epoch: 6.86 secs\n",
      "\n",
      "Saving checkpoint for epoch 17 at ./checkpoints/l2-canny-slim/ckpt-18\n",
      "Epoch 18 Batch 0 Loss 0.1882046\n",
      "Epoch 18 Loss 0.2472150\n",
      "test accuracy:  0.7513020833333334\n",
      "train accuracy:  0.8879464285714286\n",
      "Time taken for 1 epoch: 7.03 secs\n",
      "\n",
      "Saving checkpoint for epoch 18 at ./checkpoints/l2-canny-slim/ckpt-19\n",
      "Epoch 19 Batch 0 Loss 0.1824598\n",
      "Epoch 19 Loss 0.1671916\n",
      "test accuracy:  0.7273763020833334\n",
      "train accuracy:  0.8879464285714286\n",
      "Time taken for 1 epoch: 6.80 secs\n",
      "\n",
      "Saving checkpoint for epoch 19 at ./checkpoints/l2-canny-slim/ckpt-20\n",
      "Epoch 20 Batch 0 Loss 0.1993117\n",
      "Epoch 20 Loss 0.1647862\n",
      "test accuracy:  0.7379557291666666\n",
      "train accuracy:  0.8861607142857143\n",
      "Time taken for 1 epoch: 6.70 secs\n",
      "\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/l2-canny-slim/ckpt-21\n",
      "Epoch 21 Batch 0 Loss 0.0857333\n",
      "Epoch 21 Loss 0.1985715\n",
      "test accuracy:  0.76123046875\n",
      "train accuracy:  0.9004464285714285\n",
      "Time taken for 1 epoch: 6.88 secs\n",
      "\n",
      "Saving checkpoint for epoch 21 at ./checkpoints/l2-canny-slim/ckpt-22\n",
      "Epoch 22 Batch 0 Loss 0.1799403\n",
      "Epoch 22 Loss 0.1924142\n",
      "test accuracy:  0.75927734375\n",
      "train accuracy:  0.8946428571428572\n",
      "Time taken for 1 epoch: 6.91 secs\n",
      "\n",
      "Saving checkpoint for epoch 22 at ./checkpoints/l2-canny-slim/ckpt-23\n",
      "Epoch 23 Batch 0 Loss 0.2133699\n",
      "Epoch 23 Loss 0.2463355\n",
      "test accuracy:  0.7316080729166666\n",
      "train accuracy:  0.9111607142857143\n",
      "Time taken for 1 epoch: 6.71 secs\n",
      "\n",
      "Saving checkpoint for epoch 23 at ./checkpoints/l2-canny-slim/ckpt-24\n",
      "Epoch 24 Batch 0 Loss 0.1957983\n",
      "Epoch 24 Loss 0.1645913\n",
      "test accuracy:  0.76123046875\n",
      "train accuracy:  0.9116071428571428\n",
      "Time taken for 1 epoch: 6.88 secs\n",
      "\n",
      "Saving checkpoint for epoch 24 at ./checkpoints/l2-canny-slim/ckpt-25\n",
      "Epoch 25 Batch 0 Loss 0.1135497\n",
      "Epoch 25 Loss 0.1813603\n",
      "test accuracy:  0.7291666666666666\n",
      "train accuracy:  0.9120535714285715\n",
      "Time taken for 1 epoch: 7.48 secs\n",
      "\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/l2-canny-slim/ckpt-26\n",
      "Epoch 26 Batch 0 Loss 0.0912113\n",
      "Epoch 26 Loss 0.1671261\n",
      "test accuracy:  0.7666015625\n",
      "train accuracy:  0.9058035714285714\n",
      "Time taken for 1 epoch: 6.70 secs\n",
      "\n",
      "Saving checkpoint for epoch 26 at ./checkpoints/l2-canny-slim/ckpt-27\n",
      "Epoch 27 Batch 0 Loss 0.1166001\n",
      "Epoch 27 Loss 0.1510671\n",
      "test accuracy:  0.7669270833333334\n",
      "train accuracy:  0.9120535714285715\n",
      "Time taken for 1 epoch: 6.83 secs\n",
      "\n",
      "Saving checkpoint for epoch 27 at ./checkpoints/l2-canny-slim/ckpt-28\n",
      "Epoch 28 Batch 0 Loss 0.0809072\n",
      "Epoch 28 Loss 0.1741036\n",
      "test accuracy:  0.74462890625\n",
      "train accuracy:  0.915625\n",
      "Time taken for 1 epoch: 7.02 secs\n",
      "\n",
      "Saving checkpoint for epoch 28 at ./checkpoints/l2-canny-slim/ckpt-29\n",
      "Epoch 29 Batch 0 Loss 0.2278342\n",
      "Epoch 29 Loss 0.0873324\n",
      "test accuracy:  0.7190755208333334\n",
      "train accuracy:  0.9111607142857143\n",
      "Time taken for 1 epoch: 6.90 secs\n",
      "\n",
      "Saving checkpoint for epoch 29 at ./checkpoints/l2-canny-slim/ckpt-30\n",
      "Epoch 30 Batch 0 Loss 0.1602972\n",
      "Epoch 30 Loss 0.1783625\n",
      "test accuracy:  0.7332356770833334\n",
      "train accuracy:  0.9236607142857143\n",
      "Time taken for 1 epoch: 6.88 secs\n",
      "\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/l2-canny-slim/ckpt-31\n",
      "Epoch 31 Batch 0 Loss 0.1230187\n",
      "Epoch 31 Loss 0.0602807\n",
      "test accuracy:  0.7462565104166666\n",
      "train accuracy:  0.9223214285714286\n",
      "Time taken for 1 epoch: 6.81 secs\n",
      "\n",
      "Saving checkpoint for epoch 31 at ./checkpoints/l2-canny-slim/ckpt-32\n",
      "Epoch 32 Batch 0 Loss 0.1221177\n",
      "Epoch 32 Loss 0.0581368\n",
      "test accuracy:  0.7384440104166666\n",
      "train accuracy:  0.9258928571428572\n",
      "Time taken for 1 epoch: 6.74 secs\n",
      "\n",
      "Saving checkpoint for epoch 32 at ./checkpoints/l2-canny-slim/ckpt-33\n",
      "Epoch 33 Batch 0 Loss 0.0538799\n",
      "Epoch 33 Loss 0.1899580\n",
      "test accuracy:  0.7330729166666666\n",
      "train accuracy:  0.9169642857142857\n",
      "Time taken for 1 epoch: 6.78 secs\n",
      "\n",
      "Saving checkpoint for epoch 33 at ./checkpoints/l2-canny-slim/ckpt-34\n",
      "Epoch 34 Batch 0 Loss 0.0942308\n",
      "Epoch 34 Loss 0.0760696\n",
      "test accuracy:  0.7433268229166666\n",
      "train accuracy:  0.9191964285714286\n",
      "Time taken for 1 epoch: 6.78 secs\n",
      "\n",
      "Saving checkpoint for epoch 34 at ./checkpoints/l2-canny-slim/ckpt-35\n",
      "Epoch 35 Batch 0 Loss 0.0684327\n",
      "Epoch 35 Loss 0.1268995\n",
      "test accuracy:  0.7340494791666666\n",
      "train accuracy:  0.9241071428571429\n",
      "Time taken for 1 epoch: 6.73 secs\n",
      "\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/l2-canny-slim/ckpt-36\n",
      "Epoch 36 Batch 0 Loss 0.0819949\n",
      "Epoch 36 Loss 0.0869754\n",
      "test accuracy:  0.7384440104166666\n",
      "train accuracy:  0.9258928571428572\n",
      "Time taken for 1 epoch: 7.16 secs\n",
      "\n",
      "Saving checkpoint for epoch 36 at ./checkpoints/l2-canny-slim/ckpt-37\n",
      "Epoch 37 Batch 0 Loss 0.1617251\n",
      "Epoch 37 Loss 0.1688799\n",
      "test accuracy:  0.7303059895833334\n",
      "train accuracy:  0.9308035714285714\n",
      "Time taken for 1 epoch: 6.76 secs\n",
      "\n",
      "Saving checkpoint for epoch 37 at ./checkpoints/l2-canny-slim/ckpt-38\n",
      "Epoch 38 Batch 0 Loss 0.1134271\n",
      "Epoch 38 Loss 0.1068372\n",
      "test accuracy:  0.74853515625\n",
      "train accuracy:  0.9321428571428572\n",
      "Time taken for 1 epoch: 6.85 secs\n",
      "\n",
      "Saving checkpoint for epoch 38 at ./checkpoints/l2-canny-slim/ckpt-39\n",
      "Epoch 39 Batch 0 Loss 0.0794483\n",
      "Epoch 39 Loss 0.0973714\n",
      "test accuracy:  0.7316080729166666\n",
      "train accuracy:  0.93125\n",
      "Time taken for 1 epoch: 6.63 secs\n",
      "\n",
      "Saving checkpoint for epoch 39 at ./checkpoints/l2-canny-slim/ckpt-40\n",
      "Epoch 40 Batch 0 Loss 0.1638437\n",
      "Epoch 40 Loss 0.0359397\n",
      "test accuracy:  0.73291015625\n",
      "train accuracy:  0.9352678571428571\n",
      "Time taken for 1 epoch: 6.71 secs\n",
      "\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/l2-canny-slim/ckpt-41\n",
      "Epoch 41 Batch 0 Loss 0.1682427\n",
      "Epoch 41 Loss 0.2140995\n",
      "test accuracy:  0.7462565104166666\n",
      "train accuracy:  0.9330357142857143\n",
      "Time taken for 1 epoch: 6.99 secs\n",
      "\n",
      "Saving checkpoint for epoch 41 at ./checkpoints/l2-canny-slim/ckpt-42\n",
      "Epoch 42 Batch 0 Loss 0.1194823\n",
      "Epoch 42 Loss 0.1228958\n",
      "test accuracy:  0.7408854166666666\n",
      "train accuracy:  0.9321428571428572\n",
      "Time taken for 1 epoch: 6.80 secs\n",
      "\n",
      "Saving checkpoint for epoch 42 at ./checkpoints/l2-canny-slim/ckpt-43\n",
      "Epoch 43 Batch 0 Loss 0.1328493\n",
      "Epoch 43 Loss 0.0686228\n",
      "test accuracy:  0.705078125\n",
      "train accuracy:  0.9383928571428571\n",
      "Time taken for 1 epoch: 6.79 secs\n",
      "\n",
      "Saving checkpoint for epoch 43 at ./checkpoints/l2-canny-slim/ckpt-44\n",
      "Epoch 44 Batch 0 Loss 0.1110060\n",
      "Epoch 44 Loss 0.1956522\n",
      "test accuracy:  0.7301432291666666\n",
      "train accuracy:  0.9299107142857143\n",
      "Time taken for 1 epoch: 6.82 secs\n",
      "\n",
      "Saving checkpoint for epoch 44 at ./checkpoints/l2-canny-slim/ckpt-45\n",
      "Epoch 45 Batch 0 Loss 0.0764203\n",
      "Epoch 45 Loss 0.1097913\n",
      "test accuracy:  0.7439778645833334\n",
      "train accuracy:  0.9370535714285714\n",
      "Time taken for 1 epoch: 6.87 secs\n",
      "\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/l2-canny-slim/ckpt-46\n",
      "Epoch 46 Batch 0 Loss 0.0724431\n",
      "Epoch 46 Loss 0.1190091\n",
      "test accuracy:  0.7275390625\n",
      "train accuracy:  0.9370535714285714\n",
      "Time taken for 1 epoch: 6.72 secs\n",
      "\n",
      "Saving checkpoint for epoch 46 at ./checkpoints/l2-canny-slim/ckpt-47\n",
      "Epoch 47 Batch 0 Loss 0.0638624\n",
      "Epoch 47 Loss 0.1102035\n",
      "test accuracy:  0.7333984375\n",
      "train accuracy:  0.9433035714285715\n",
      "Time taken for 1 epoch: 8.20 secs\n",
      "\n",
      "Saving checkpoint for epoch 47 at ./checkpoints/l2-canny-slim/ckpt-48\n",
      "Epoch 48 Batch 0 Loss 0.0951535\n",
      "Epoch 48 Loss 0.1616636\n",
      "test accuracy:  0.7158203125\n",
      "train accuracy:  0.9379464285714286\n",
      "Time taken for 1 epoch: 6.72 secs\n",
      "\n",
      "Saving checkpoint for epoch 48 at ./checkpoints/l2-canny-slim/ckpt-49\n",
      "Epoch 49 Batch 0 Loss 0.1305746\n",
      "Epoch 49 Loss 0.0350581\n",
      "test accuracy:  0.7176106770833334\n",
      "train accuracy:  0.9459821428571429\n",
      "Time taken for 1 epoch: 6.95 secs\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "checkpoints/l2-canny-slim/ckpt-50_temp/part-00000-of-00001.data-00000-of-00001.tempstate7244357818491759972; No space left on device [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6130e77012d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcnt_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mckpt_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Saving checkpoint for epoch {epoch} at {ckpt_save_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/checkpoint_management.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, checkpoint_number, check_interval)\u001b[0m\n\u001b[1;32m    805\u001b[0m           sess=session, global_step_tensor=checkpoint_number)\n\u001b[1;32m    806\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s-%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;31m# If this is an overwritten checkpoint we were previously tracking, delete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \"\"\"\n\u001b[1;32m   2010\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1217\u001b[0;31m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0m\u001b[1;32m   1218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1161\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0;31m# device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1714\u001b[0m       return save_v2_eager_fallback(\n\u001b[1;32m   1715\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1717\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1734\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1736\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1737\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: checkpoints/l2-canny-slim/ckpt-50_temp/part-00000-of-00001.data-00000-of-00001.tempstate7244357818491759972; No space left on device [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "for epoch in range(1500):\n",
    "    start = time.time()\n",
    "    loss = 0\n",
    "    train_acc = 0\n",
    "    accuracy = 0\n",
    "    cnt = 1\n",
    "    cnt_train = 1\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch} at {ckpt_save_path}')\n",
    "    \n",
    "    for batch, data in enumerate(train_ds_with_label):\n",
    "        loss, logit = train_step_classification(get_augmenter(**contrastive_augmentation)(data[0]), data[1])\n",
    "        logit = np.squeeze(logit)\n",
    "        # print(tf.image.rgb_to_grayscale(get_augmenter(**contrastive_augmentation)(data[0])))\n",
    "        train_acc += binary_accuracy(data[1], logit).numpy()\n",
    "        cnt_train += 1\n",
    "        \n",
    "        if batch % 50 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {loss:.7f}')\n",
    "    for img, label in val_ds_with_label:\n",
    "        accuracy += test_step(get_augmenter_val(**contrastive_augmentation)(img), label).numpy()\n",
    "        cnt+=1\n",
    "        \n",
    "    print(f'Epoch {epoch + 1} Loss {loss:.7f}')\n",
    "    print('test accuracy: ', accuracy/cnt)\n",
    "    print('train accuracy: ', train_acc/cnt_train)\n",
    "\n",
    "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e64c9",
   "metadata": {},
   "source": [
    "# Reload model with highest validation accuracy and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c4fa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8e4497a110>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.restore(checkpoint_path + '/ckpt-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8284ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 224, 224, 3)\n",
      "(100, 224, 224, 1, 2)\n",
      "[1 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0\n",
      " 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "header = ['id', 'label']\n",
    "x_test = np.load('/home/haowei/CS565600_Deep_Learning/DL_comp4/dataset/x_test_imagenet.npy')\n",
    "print(x_test.shape)\n",
    "x_test = tf.image.rgb_to_grayscale(x_test)\n",
    "x_test = tf.image.sobel_edges(x_test)\n",
    "print(x_test.shape)\n",
    "x_test = tf.reshape(x_test, [100, 224, 224, 2])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.batch(64, drop_remainder=False)\n",
    "res = np.squeeze(K.round(tf.nn.sigmoid(model.predict(test_dataset))).numpy()).astype(int)\n",
    "\n",
    "print(res)\n",
    "with open('res-canny-slim.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for i, y in enumerate(res):\n",
    "        writer.writerow([i, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84598439",
   "metadata": {},
   "source": [
    "# Describe what you have done to improve your training accuracy in detail.\n",
    "* We used the model architecture in above for the baseline, and try to tune the hyperparameter and do different image augmentation to improve our testing performance.\n",
    "* For hyperparameter tuning, we tried different combination of epsilon and learning rate while using Adam as optimizer. We tried epsilon=1e-9, 1e-8, 1e-7; lr=1e-3, 1e-2. And we observed the validation loss, finally, we choose epsilon=1e-8 and lr=1e-3.\n",
    "* For image augmentation, we noticed that when we decrease the information in the poison image which the model learned, we can let our model more general. So, beside some basic augmentation skill, we also tried \"gray scale\" and \"sobel edge\" to make our image more general for machine to identify.\n",
    "* Because it is a binary problem, we thought if we just evaluate our model by public testing performance, it would overfit, so, we add l2 norm as regularization. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "582a547d56616ed5ded758bd597d037ed2282210a9e90cbdefccd6d7e4528f9e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('py37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
